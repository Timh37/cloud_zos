{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0ff811-96d3-4c4b-ae9c-5c34ea682794",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14004/2568689562.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import cftime\n",
    "import os\n",
    "import intake\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "from xmip.utils import google_cmip_col\n",
    "from xmip.preprocessing import rename_cmip6, promote_empty_dims, correct_coordinates, broadcast_lonlat, correct_lon, correct_units, fix_metadata,_drop_coords\n",
    "from xmip.postprocessing import combine_datasets,_concat_sorted_time, match_metrics\n",
    "from cmip_catalogue_operations import reduce_cat_to_max_num_realizations, drop_older_versions, search_cloud\n",
    "from cmip_ds_dict_operations import generate_dict_of_datasets, drop_duplicate_timesteps, drop_coords, drop_incomplete, drop_vars, create_regridder_dict, get_availability_from_ddicts\n",
    "import xesmf as xe\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() #list stores, stripp zarr from filename, load "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0862814-5679-4a0e-9893-d46cbd0c8076",
   "metadata": {},
   "source": [
    "Various functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dea532-a2b2-4284-bbd5-36f3242868bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_combined_preprocessing(ds): #'combined_preprocessing' from xmip is problematic for some datasets\n",
    "    ds = rename_cmip6(ds) # fix naming\n",
    "    ds = promote_empty_dims(ds) # promote empty dims to actual coordinates\n",
    "    ds = correct_coordinates(ds) # demote coordinates from data_variables\n",
    "    ds = broadcast_lonlat(ds) # broadcast lon/lat\n",
    "    ds = correct_lon(ds) # shift all lons to consistent 0-360\n",
    "    ds = correct_units(ds) # fix the units\n",
    "    ''' part of combined preprocessing\n",
    "    ds = parse_lon_lat_bounds(ds) # rename the `bounds` according to their style (bound or vertex)\n",
    "    ds = sort_vertex_order(ds) # sort verticies in a consistent manner\n",
    "    ds = maybe_convert_bounds_to_vertex(ds) # convert vertex into bounds and vice versa, so both are available\n",
    "    ds = maybe_convert_vertex_to_bounds(ds)\n",
    "    '''\n",
    "    ds = fix_metadata(ds)\n",
    "    ds = ds.drop_vars(_drop_coords, errors=\"ignore\")\n",
    "    return ds\n",
    "\n",
    "def cleanup_datasets_in_dict(ddict):\n",
    "    ddict = drop_duplicate_timesteps(ddict) #remove duplicate timesteps if present\n",
    "    ddict = drop_coords(ddict,['vertices_latitude','vertices_longitude']) #remove coords & variables\n",
    "    ddict = drop_vars(ddict,['vertices_latitude','vertices_longitude'])\n",
    "\n",
    "    for k,v in ddict.items():\n",
    "        if 'dcpp_init_year' in v:\n",
    "            ddict[k] = v.isel(dcpp_init_year=0,drop=True)\n",
    "    return ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac55f9b-d5c3-46e7-8167-6ca6b216e764",
   "metadata": {},
   "source": [
    "Configure the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295422c2-6743-4393-93e8-6dd2d478660b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_var = 'psl' #variables to process\n",
    "#ssps = ['ssp585']\n",
    "ssps = ['ssp126','ssp245','ssp370','ssp585'] #SSPs to process #(TODO: loop over multiple, streamline code!)\n",
    "\n",
    "regrid = True\n",
    "target_grid = xr.Dataset(\n",
    "    {\"lat\": ([\"lat\"], np.arange(-90, 90, 1), {\"units\": \"degrees_north\"}),\n",
    "     \"lon\": ([\"lon\"], np.arange(0, 360, 1), {\"units\": \"degrees_east\"}),})\n",
    "target_grid.attrs['name'] = '1x1' #target grid assumed to be regular\n",
    "\n",
    "zos_path = 'gs://leap-persistent/timh37/CMIP6/zos_1x1'\n",
    "\n",
    "#models to exclude a-priori becaue of preprocessing issues (to be sorted out?)\n",
    "models_to_exclude = ['AWI-CM-1-1-MR','AWI-ESM-1-1-LR','AWI-CM-1-1-LR','KIOST-ESM']\n",
    "\n",
    "min_pic_numYears = 150\n",
    "\n",
    "output_period = ['1950','2500']\n",
    "\n",
    "output_path = 'gs://leap-persistent/timh37/CMIP6/'\n",
    "\n",
    "overwrite_existing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2066879-0d17-4c2e-bcd6-dba3da23b756",
   "metadata": {},
   "source": [
    "Query datasets, put into dictionaries of datasets, and preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0d6af3-eab5-4cc8-95cc-f5cf417a8f5e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='578' class='' max='578' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [578/578 00:30&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='810' class='' max='810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [810/810 00:35&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate timesteps for:EC-Earth3-Veg.gr.Amon.r5i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/pydantic/main.py:1114: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/pydantic/deprecated/decorator.py:222: DeprecationWarning: cdf_kwargs and zarr_kwargs are deprecated and will be removed in a future version. Please use xarray_open_kwargs instead.\n",
      "  return self.raw_function(**d, **var_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='688' class='' max='688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [688/688 00:28&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r5i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/pydantic/main.py:1114: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/pydantic/deprecated/decorator.py:222: DeprecationWarning: cdf_kwargs and zarr_kwargs are deprecated and will be removed in a future version. Please use xarray_open_kwargs instead.\n",
      "  return self.raw_function(**d, **var_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='670' class='' max='670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [670/670 00:28&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n"
     ]
    }
   ],
   "source": [
    "#search & load hist+ssp dictionary of datasets\n",
    "ssp_cats = defaultdict(dict)\n",
    "for s,ssp in enumerate(ssps):\n",
    "    cat = search_cloud(query_var,['historical',ssp],'Amon',['source_id', 'member_id','grid_label']) #done per SSP because availability may be different\n",
    "    ssp_cats[ssp] = cat\n",
    "\n",
    "#put ssp cats together (AFAIK no other way but to copy an existing catalog and to assign the concatenation of the dataframes inside each separate catalogue as the new dataframe)   \n",
    "ssp_cats_merged = ssp_cats[ssps[0]] \n",
    "ssp_cats_merged.esmcat._df = pd.concat([v.df for k,v in ssp_cats.items()],ignore_index=True).drop_duplicates(ignore_index=True)\n",
    "ssp_cats_merged = reduce_cat_to_max_num_realizations(ssp_cats_merged) #per model, select grid and 'ipf' combination providing most realizations (needs to be applied to both SSPs together to ensure the same variants are used under both scenarios)\n",
    "\n",
    "ssp_ddicts = defaultdict(dict) #not sure when/this is needed?\n",
    "for s,ssp in enumerate(ssps):\n",
    "    ssp_cat = ssp_cats_merged.search(experiment_id=['historical',ssp],table_id='Amon',variable_id=query_var,require_all_on=['source_id', 'member_id','grid_label']) #retrieve ssp cat from reduced catalogue\n",
    "    ssp_ddict = generate_dict_of_datasets(ssp_cat,models_to_exclude,partial_combined_preprocessing)\n",
    "    ssp_ddict = cleanup_datasets_in_dict(ssp_ddict)    \n",
    "    \n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}): #concatenate historical and SSP\n",
    "        ssp_ddict = combine_datasets(ssp_ddict,_concat_sorted_time,match_attrs =['source_id', 'grid_label','table_id','variant_label','variable_id'],combine_func_kwargs={'join':'inner','coords':'minimal','compat':'override'})    \n",
    "    \n",
    "    ssp_ddict = drop_duplicate_timesteps(ssp_ddict) #remove overlap between historical and ssp experiments, which sometimes exists, again using 'drop_duplicate_timesteps'\n",
    "\n",
    "    #intermediate step to drop incomplete time series for hist+ssp, to-do: put in a separate function?\n",
    "    inconsistent_experiment_calendars = [] #identify if historical and SSP experiments have different calendars, which causes issues later on\n",
    "    for k,v in ssp_ddict.items():\n",
    "        try:\n",
    "            v.time[-1] - v.time[0]\n",
    "        except: #unify calendars \n",
    "            not_prolgreg = np.where(np.array([type(i) for i in v.time.values]) != cftime._cftime.DatetimeProlepticGregorian)[0] #find where calendar is not proleptic gregorian\n",
    "            converted_time = v.isel(time=not_prolgreg).convert_calendar('proleptic_gregorian',use_cftime=True).time #convert at these indices\n",
    "            newtime = v.time.values #replace old time index with new values\n",
    "            newtime[not_prolgreg] = converted_time.values\n",
    "            ssp_ddict[k]['time'] = newtime\n",
    "        \n",
    "    ssp_ddict = drop_incomplete(ssp_ddict) #remove historical+ssp timeseries which are not montonically increasing or have large timegaps (based on checks in CMIP6-LEAP-feadstock\n",
    "    ssp_ddict.pop('MPI-ESM1-2-HR.gn.Amon.r2i1p1f1.psl') #grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding\n",
    "    ssp_ddicts[ssp] = ssp_ddict #add to dictionary of dictionaries of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba18acd9-ca11-4c58-a6d0-517d89ebb4a2",
   "metadata": {},
   "source": [
    "Regrid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a4266dc-965a-403c-a114-33de57a4c0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb2d6bad45c42999c74530f840ffea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "regridder_dict = {}\n",
    "regridder_dict = create_regridder_dict(ssp_ddicts,target_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "989c4b73-3556-4ab5-87b2-d30df8257c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae9f5fb6c814bb8a7a8d19ff250c8c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9570a5de4b44d687f76917d3088530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02367084c7be489dbacf58776b506834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81fe52edc3fa471c915b29ce93074558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s,ssp in enumerate(ssps):\n",
    "    print(ssp)\n",
    "    ssp_ddict = ssp_ddicts[ssp]\n",
    "    for key,ds in tqdm(ssp_ddict.items()):\n",
    "        regridder = regridder_dict[ds.attrs['source_id']] #select regridder for this source_id\n",
    "        regridded_ds = regridder(ds, keep_attrs=True) #do the regridding\n",
    "        ssp_ddicts[ssp][key] = regridded_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf1172-9d67-48e8-9850-b818f1080018",
   "metadata": {},
   "source": [
    "Find matching ocean/land mask from corresponding 'zos' files, these are needed because IBE is based on pressure anomalies relative to the ocean-area weighted mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23705009-7207-4163-87c8-f00284d430fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f549e567e3474f4eb87a38ffd861db09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/coding/times.py:1001: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/indexing.py:514: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(self.get_duck_array(), dtype=dtype, copy=copy)\n"
     ]
    }
   ],
   "source": [
    "model_masks = defaultdict(dict)\n",
    "psl_models = np.unique(np.hstack([[ds.attrs['source_id'] for ds in dataset_dict.values()] for dataset_dict in ssp_ddicts.values()]))\n",
    "\n",
    "zos_path = zos_path\n",
    "\n",
    "for model in tqdm(psl_models):\n",
    "    try:\n",
    "        fns = fs.ls(os.path.join(zos_path,model))\n",
    "        zos_ds = xr.open_dataset('gs://'+fns[0],engine='zarr')\n",
    "        model_masks[str(model)] = np.isfinite(zos_ds.zos.isel(time=0)).isel(member_id=0,drop=True)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37e5d3-8600-4204-b45c-05d666c5504b",
   "metadata": {},
   "source": [
    "Compute IBE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5858403-13ae-4d4a-8060-e37d77e5c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "[LON,LAT] = np.meshgrid(target_grid.lon,target_grid.lat)\n",
    "aweights = np.cos(np.deg2rad(LAT)) #come up with weights for regular 1x1 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88525783-9e82-403d-aea2-fb25222de3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94780fd961bc4f9b855ca7935d132878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9538b6eff0fe4c0dafe5aab14588e259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d4f1fec867499d9ba63b67690c34fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/343 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be44d4581ef94bb9b77f00535c3b87f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/334 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ibe_ddicts = defaultdict(dict)\n",
    "\n",
    "for s,ssp in enumerate(ssps):\n",
    "    print(ssp)\n",
    "    ibe_ddict = defaultdict(dict)\n",
    "    \n",
    "    ssp_ddict = ssp_ddicts[ssp]\n",
    "    for key,ds in tqdm(ssp_ddict.items()):\n",
    "        if ds.source_id not in list(model_masks.keys()):\n",
    "            continue\n",
    "        else:\n",
    "            mask = model_masks[ds.source_id]\n",
    "            ds['psl'] = ds['psl'].where(mask,np.nan) #add land mask based on matching preprocessed zos file\n",
    "            ds['aweights'] = (('lat','lon'),aweights) #add latitude-based area weights\n",
    "            ibe = (1/(9.81 * 1025)) * -(ds['psl'] - ds['psl'].weighted(ds.aweights).mean(('lon','lat'))) #from Stammer 2008\n",
    "            \n",
    "            ibe = ibe.to_dataset() #turn into new dataset\n",
    "            ibe = ibe.rename({'psl':'ibe'})\n",
    "            ibe.attrs = ds.attrs \n",
    "    \n",
    "            ibe_ddict[key] = ibe #put into dictionary\n",
    "    ibe_ddicts[ssp] = ibe_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f929ab9-6516-4d1b-81f0-93f7eabdc26c",
   "metadata": {},
   "source": [
    "Print number of available models & members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cd36a6-1b9c-4ff5-808b-eaff65bae57e",
   "metadata": {},
   "source": [
    "availability = get_availability_from_ddicts(ibe_ddicts)\n",
    "for k,v in availability.items():\n",
    "    print('')\n",
    "    print(k)\n",
    "    for model in np.unique(np.hstack([[ds.attrs['source_id'] for ds in dataset_dict.values()] for dataset_dict in ibe_ddicts.values()])):\n",
    "        print(str(len(v[model])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689107bf-4f09-406b-a890-262ca8e5780c",
   "metadata": {},
   "source": [
    "Store output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68fae5c5-a6b8-4f49-8037-dd6a548f6a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeda93a02a154a63a5a44b959ba69c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/320 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s,ssp in enumerate(ssps):\n",
    "    print(ssp)\n",
    "    ibe_ddict = ibe_ddicts[ssp]\n",
    "    for key,ds in tqdm(ibe_ddict.items()):\n",
    "        \n",
    "        ds = ds.sel(time=slice(output_period[0],output_period[1])) #select output period\n",
    "        ds = ds[['ibe']] #get rid of 'area' that is a variable in some datasets\n",
    "        ds_name = key+'.hist_'+ssp+'.'+str(ds.time[0].dt.year.values)+'-'+str(ds.time[-1].dt.year.values) #generate file name\n",
    "\n",
    "        output_fn = os.path.join(output_path,'ibe'+['','_'+target_grid.attrs['name']][regrid],ds.source_id,ds_name)\n",
    "        \n",
    "        if overwrite_existing or not fs.exists(output_fn):\n",
    "            #store:\n",
    "            try:\n",
    "                ds.to_zarr(output_fn,mode='w') #fails if chunks are not uniform due to time concatenation\n",
    "            except:\n",
    "                ds['ibe'] = ds['ibe'].chunk({'time':'auto'})\n",
    "                ds.to_zarr(output_fn,mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6679b81-449a-4f98-af54-6ef5d662345f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['leap-persistent/timh37/CMIP6/ibe_1x1/ACCESS-CM2',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/ACCESS-ESM1-5',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CAMS-CSM1-0',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CAS-ESM2-0',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CESM2',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CESM2-FV2',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CESM2-WACCM',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CIESM',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CMCC-CM2-SR5',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CMCC-ESM2',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CNRM-CM6-1',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CNRM-CM6-1-HR',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CNRM-ESM2-1',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CanESM5',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/CanESM5-CanOE',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/EC-Earth3',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/EC-Earth3-CC',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/EC-Earth3-Veg',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/EC-Earth3-Veg-LR',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/FGOALS-g3',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/FIO-ESM-2-0',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/GFDL-ESM4',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/GISS-E2-1-G',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/HadGEM3-GC31-LL',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/HadGEM3-GC31-MM',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/INM-CM4-8',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/INM-CM5-0',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/IPSL-CM6A-LR',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/MIROC-ES2L',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/MIROC6',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/MPI-ESM1-2-HR',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/MPI-ESM1-2-LR',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/MRI-ESM2-0',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/NorESM2-LM',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/NorESM2-MM',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/TaiESM1',\n",
       " 'leap-persistent/timh37/CMIP6/ibe_1x1/UKESM1-0-LL']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs.ls(os.path.join(output_path+'ibe_1x1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ac1c3-f79f-42a7-b456-614270d4fe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
