{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f0ff811-96d3-4c4b-ae9c-5c34ea682794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import cftime\n",
    "import os\n",
    "import intake\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm.autonotebook import tqdm\n",
    "from xmip.utils import google_cmip_col\n",
    "from xmip.preprocessing import rename_cmip6, promote_empty_dims, correct_coordinates, broadcast_lonlat, correct_lon, correct_units, fix_metadata,_drop_coords\n",
    "from xmip.postprocessing import combine_datasets,_concat_sorted_time, match_metrics\n",
    "from cmip_catalogue_operations import reduce_cat_to_max_num_realizations, drop_older_versions, search_cloud\n",
    "from cmip_ds_dict_operations import generate_dict_of_datasets, drop_duplicate_timesteps, drop_coords, drop_incomplete, drop_vars, create_regridder_dict, regrid_datasets_in_ddict,select_period, create_land_mask_dict, fix_inconsistent_calendars\n",
    "import xesmf as xe\n",
    "import gcsfs\n",
    "fs = gcsfs.GCSFileSystem() #list stores, stripp zarr from filename, load "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0862814-5679-4a0e-9893-d46cbd0c8076",
   "metadata": {},
   "source": [
    "Various functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9dea532-a2b2-4284-bbd5-36f3242868bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_combined_preprocessing(ds): #'combined_preprocessing' from xmip is problematic for some datasets\n",
    "    ds = rename_cmip6(ds) # fix naming\n",
    "    ds = promote_empty_dims(ds) # promote empty dims to actual coordinates\n",
    "    ds = correct_coordinates(ds) # demote coordinates from data_variables\n",
    "    ds = broadcast_lonlat(ds) # broadcast lon/lat\n",
    "    ds = correct_lon(ds) # shift all lons to consistent 0-360\n",
    "    ds = correct_units(ds) # fix the units\n",
    "    ''' part of combined preprocessing\n",
    "    ds = parse_lon_lat_bounds(ds) # rename the `bounds` according to their style (bound or vertex)\n",
    "    ds = sort_vertex_order(ds) # sort verticies in a consistent manner\n",
    "    ds = maybe_convert_bounds_to_vertex(ds) # convert vertex into bounds and vice versa, so both are available\n",
    "    ds = maybe_convert_vertex_to_bounds(ds)\n",
    "    '''\n",
    "    ds = fix_metadata(ds)\n",
    "    ds = ds.drop_vars(_drop_coords, errors=\"ignore\")\n",
    "    return ds\n",
    "\n",
    "def cleanup_datasets_in_dict(ddict):\n",
    "    ddict = drop_duplicate_timesteps(ddict) #remove duplicate timesteps if present\n",
    "    ddict = drop_coords(ddict,['vertices_latitude','vertices_longitude']) #remove coords & variables\n",
    "    ddict = drop_vars(ddict,['vertices_latitude','vertices_longitude'])\n",
    "\n",
    "    ddict_out = defaultdict(dict)\n",
    "    for k,v in ddict.items():\n",
    "        \n",
    "        v = v.isel(dcpp_init_year=0,drop=True,missing_dims='ignore')\n",
    "        \n",
    "        if v.source_id=='INM-CM4-8':\n",
    "            in_russia_blob = ((v.lat>=40)&(v.lat<=70)&(v.lon>=65)&(v.lon<=120))\n",
    "            in_us_blob = ((v.lat>=40)&(v.lat<=50)&(v.lon>=260)&(v.lon<=290))\n",
    "            v = v.where(v.lat>=-79).where(in_russia_blob==False).where(in_us_blob==False) \n",
    "\n",
    "        if v.source_id=='MPI-ESM1-2-HR':\n",
    "            if v.member_id == 'r2i1p1f1':\n",
    "                print('Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: '+k)\n",
    "                continue\n",
    "        \n",
    "        if 'x' in v:\n",
    "            if len(v['x'])==0:\n",
    "                print('Longitude and/or latitude dimensions have length 0, dropping: '+k)\n",
    "                continue\n",
    "        if 'y' in v:\n",
    "            if len(v['y'])==0:\n",
    "                print('Longitude and/or latitude dimensions have length 0, dropping: '+k)\n",
    "                continue\n",
    "     \n",
    "        ddict_out[k] = v\n",
    "\n",
    "    return ddict_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac55f9b-d5c3-46e7-8167-6ca6b216e764",
   "metadata": {},
   "source": [
    "Configure the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "295422c2-6743-4393-93e8-6dd2d478660b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_var = 'psl' #variables to process\n",
    "query_ssps = ['ssp126','ssp245','ssp370','ssp585'] #SSPs to use for data query\n",
    "\n",
    "ssps_to_process = ['ssp126','ssp245','ssp370','ssp585'] #SSPs to process data for \n",
    "\n",
    "\n",
    "regrid = True\n",
    "target_grid = xr.Dataset(\n",
    "    {\"lat\": ([\"lat\"], np.arange(-90, 90, 1), {\"units\": \"degrees_north\"}),\n",
    "     \"lon\": ([\"lon\"], np.arange(0, 360, 1), {\"units\": \"degrees_east\"}),})\n",
    "target_grid.attrs['name'] = '1x1' #target grid assumed to be regular\n",
    "\n",
    "zos_path = 'gs://leap-persistent/timh37/CMIP6/zos_1x1'\n",
    "\n",
    "models_to_exclude = ['AWI-CM-1-1-MR','KIOST-ESM'] #models to exclude a-priori becaue of preprocessing/data issues\n",
    "\n",
    "min_pic_numYears = 150\n",
    "\n",
    "output_period = ['1980','2500']\n",
    "\n",
    "output_path = 'gs://leap-persistent/timh37/CMIP6/'\n",
    "\n",
    "overwrite_existing = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2066879-0d17-4c2e-bcd6-dba3da23b756",
   "metadata": {},
   "source": [
    "Query datasets, put into dictionaries of datasets, and preprocess:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c0d6af3-eab5-4cc8-95cc-f5cf417a8f5e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp126\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='580' class='' max='580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [580/580 00:26&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/CMIP/MPI-M/MPI-ESM1-2-HR/historical/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: ScenarioMIP.DWD.MPI-ESM1-2-HR.ssp126.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/ScenarioMIP/DWD/MPI-ESM1-2-HR/ssp126/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "ssp245\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='818' class='' max='818' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [818/818 00:35&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: ScenarioMIP.DKRZ.MPI-ESM1-2-HR.ssp245.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-HR/ssp245/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/CMIP/MPI-M/MPI-ESM1-2-HR/historical/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:EC-Earth3-Veg.gr.Amon.r5i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "ssp370\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='730' class='' max='730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [730/730 00:31&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/CMIP/MPI-M/MPI-ESM1-2-HR/historical/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: ScenarioMIP.DKRZ.MPI-ESM1-2-HR.ssp370.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/ScenarioMIP/DKRZ/MPI-ESM1-2-HR/ssp370/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r5i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n",
      "ssp585\n",
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.member_id.table_id.variable_id.grid_label.zstore.dcpp_init_year.version'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='678' class='' max='678' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [678/678 00:30&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: ScenarioMIP.DWD.MPI-ESM1-2-HR.ssp585.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/ScenarioMIP/DWD/MPI-ESM1-2-HR/ssp585/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Grid r1i1p1f1 and r2i1p1f1 are different despite same label, causes issues with regridding, therefore dropping: CMIP.MPI-M.MPI-ESM1-2-HR.historical.r2i1p1f1.Amon.psl.gn.gs://cmip6/CMIP6/CMIP/MPI-M/MPI-ESM1-2-HR/historical/r2i1p1f1/Amon/psl/gn/v20190710/.20190710\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r4i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r3i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r1i1p1f1.psl\n",
      "Dropping duplicate timesteps for:FGOALS-g3.gn.Amon.r2i1p1f1.psl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96303f21d354669bcbc4e79e32c81f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44f0bd7953c4bc89fac998691f92844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/coding/times.py:1001: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/indexing.py:514: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(self.get_duck_array(), dtype=dtype, copy=copy)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/coding/times.py:1001: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/indexing.py:514: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(self.get_duck_array(), dtype=dtype, copy=copy)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/coding/times.py:1001: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  dtype = _decode_cf_datetime_dtype(data, units, calendar, self.use_cftime)\n",
      "/srv/conda/envs/notebook/lib/python3.12/site-packages/xarray/core/indexing.py:514: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates out of range\n",
      "  return np.asarray(self.get_duck_array(), dtype=dtype, copy=copy)\n"
     ]
    }
   ],
   "source": [
    "#search & generate hist+SSPs dictionary of datasets\n",
    "ssp_cats = defaultdict(dict)\n",
    "for s,ssp in enumerate(query_ssps):\n",
    "    cat = search_cloud(query_var,['historical',ssp],'Amon',['source_id', 'member_id','grid_label']) #done per SSP because availability may be different\n",
    "    ssp_cats[ssp] = cat\n",
    "\n",
    "#put ssp cats together (AFAIK no other way but to copy an existing catalog and to assign the concatenation of the dataframes inside each separate catalogue as the new dataframe)   \n",
    "ssp_cats_merged = ssp_cats[query_ssps[0]] \n",
    "ssp_cats_merged.esmcat._df = pd.concat([v.df for k,v in ssp_cats.items()],ignore_index=True).drop_duplicates(ignore_index=True)\n",
    "\n",
    "#potentially first throw out members for which zos is unavailable? for now, let's see the overlap with 'zos' if we don't do this\n",
    "ssp_cats_merged = reduce_cat_to_max_num_realizations(ssp_cats_merged) #per model, select grid and 'ipf' combination providing most realizations (needs to be applied to both SSPs together to ensure the same variants are used under both scenarios)\n",
    "\n",
    "ssp_ddicts = defaultdict(dict) #not sure when/this is needed?\n",
    "for s,ssp in enumerate(ssps_to_process):\n",
    "    print(ssp)\n",
    "    ssp_cat = ssp_cats_merged.search(experiment_id=['historical',ssp],table_id='Amon',variable_id=query_var,require_all_on=['source_id', 'member_id','grid_label']) #retrieve ssp cat from reduced catalogue\n",
    "\n",
    "    ssp_ddict = {}\n",
    "    ssp_ddict = generate_dict_of_datasets(ssp_cat,models_to_exclude,partial_combined_preprocessing)\n",
    "    ssp_ddict = cleanup_datasets_in_dict(ssp_ddict)    \n",
    "    \n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}): #concatenate historical and SSP\n",
    "        ssp_ddict = combine_datasets(ssp_ddict,_concat_sorted_time,match_attrs =['source_id', 'grid_label','table_id','variant_label','variable_id'],combine_func_kwargs={'join':'inner','coords':'minimal','compat':'override'})    \n",
    "    \n",
    "    ssp_ddict = drop_duplicate_timesteps(ssp_ddict) #remove overlap between historical and ssp experiments, which sometimes exists, again using 'drop_duplicate_timesteps'\n",
    "    ssp_ddict = fix_inconsistent_calendars(ssp_ddict)\n",
    "    ssp_ddict = select_period(ssp_ddict,output_period[0],output_period[-1]) #select requested output period\n",
    "    ssp_ddict = drop_incomplete(ssp_ddict) #remove historical+ssp timeseries which are not montonically increasing or have large timegaps (based on checks in CMIP6-LEAP-feadstock)\n",
    "\n",
    "    ssp_ddicts[ssp] = ssp_ddict #add to dictionary of dictionaries of datasets\n",
    "\n",
    "if regrid: #if regridding\n",
    "    regridder_dict = create_regridder_dict(ssp_ddicts,target_grid) #generate xesmf regridders per model-grid combination  \n",
    "    #TO-DO: develop option to regrid to tide gauges/list of coordinates\n",
    "mask_dict = create_land_mask_dict(ssp_ddicts,zos_path) #Find matching ocean/land mask from corresponding 'zos' files, these are needed because IBE is based on pressure anomalies relative to the ocean-area weighted mean:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ae5db-a8c1-48c0-82fc-a9db38efaf6c",
   "metadata": {},
   "source": [
    "Carry out preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b5851b8-ce92-4c5f-bda7-cc26d5816151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d61f221e914f2795c37eb5febbe2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ff4bde354e4f8f8e68bc6c01ee49df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2f5eaef51b4f009a52fbce8c0b9040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77da62b3ca9a48719a1679d10737ab17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s,ssp in enumerate(ssps_to_process):\n",
    "    print(ssp)\n",
    "    ssp_ddict = ssp_ddicts[ssp]\n",
    "\n",
    "    if regrid:\n",
    "        ssp_ddict = regrid_datasets_in_ddict(ssp_ddict,regridder_dict)\n",
    "    ssp_ddicts[ssp] = ssp_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea37e5d3-8600-4204-b45c-05d666c5504b",
   "metadata": {},
   "source": [
    "Compute IBE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5858403-13ae-4d4a-8060-e37d77e5c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "[LON,LAT] = np.meshgrid(target_grid.lon,target_grid.lat)\n",
    "aweights = np.cos(np.deg2rad(LAT)) #come up with weights for regular 1x1 grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88525783-9e82-403d-aea2-fb25222de3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3ce070148e4e23a240906a5e1e70a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/289 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcad9f4553e488f8ee0af9df40920b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/408 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf9c8005b954a19915c51b9cf6145c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42821dbc25b94796ab7ecd17f95a593c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/338 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ibe_ddicts = defaultdict(dict)\n",
    "\n",
    "for s,ssp in enumerate(ssps_to_process):\n",
    "    print(ssp)\n",
    "    ibe_ddict = defaultdict(dict)\n",
    "    \n",
    "    ssp_ddict = ssp_ddicts[ssp]\n",
    "    for key,ds in tqdm(ssp_ddict.items()):\n",
    "        if ds.source_id not in list(mask_dict.keys()):\n",
    "            continue\n",
    "        else:\n",
    "            mask = mask_dict[ds.source_id]\n",
    "            ds['psl'] = ds['psl'].where(mask,np.nan) #add land mask based on matching preprocessed zos file\n",
    "            ds['aweights'] = (('lat','lon'),aweights) #add latitude-based area weights\n",
    "            ibe = (1/(9.81 * 1025)) * -(ds['psl'] - ds['psl'].weighted(ds.aweights).mean(('lon','lat'))) #from Stammer 2008\n",
    "            \n",
    "            ibe = ibe.to_dataset() #turn into new dataset\n",
    "            ibe = ibe.rename({'psl':'ibe'})\n",
    "            ibe.attrs = ds.attrs \n",
    "    \n",
    "            ibe_ddict[key] = ibe #put into dictionary\n",
    "    ibe_ddicts[ssp] = ibe_ddict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689107bf-4f09-406b-a890-262ca8e5780c",
   "metadata": {},
   "source": [
    "Store output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68fae5c5-a6b8-4f49-8037-dd6a548f6a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f2d890e4294f8e8d94b5d8520903b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd461b34d1ea4e41a183c6d3da2a894c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/399 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp370\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0c23543ad8491795a4d2fe1d6fd6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssp585\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1944786594be4c9281cfc587ebfe8a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/323 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s,ssp in enumerate(ssps_to_process):\n",
    "    print(ssp)\n",
    "    ibe_ddict = ibe_ddicts[ssp]\n",
    "    for key,ds in tqdm(ibe_ddict.items()):\n",
    "        \n",
    "        ds = ds.sel(time=slice(output_period[0],output_period[1])) #select output period\n",
    "        ds = ds[['ibe']] #get rid of 'area' that is a variable in some datasets\n",
    "        ds_name = key+'.hist_'+ssp+'.'+str(ds.time[0].dt.year.values)+'-'+str(ds.time[-1].dt.year.values) #generate file name\n",
    "\n",
    "        output_fn = os.path.join(output_path,'ibe'+['','_'+target_grid.attrs['name']][regrid],ds.source_id,ds_name)\n",
    "        \n",
    "        if overwrite_existing or not fs.exists(output_fn):\n",
    "            #store:\n",
    "            try:\n",
    "                ds.to_zarr(output_fn,mode='w') #fails if chunks are not uniform due to time concatenation\n",
    "            except:\n",
    "                ds['ibe'] = ds['ibe'].chunk({'time':'auto'})\n",
    "                ds.to_zarr(output_fn,mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ac1c3-f79f-42a7-b456-614270d4fe45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
